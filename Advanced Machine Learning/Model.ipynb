{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK6aVWL5hzQZ"
      },
      "source": [
        "#TO DO\r\n",
        "\r\n",
        "- ~~**change batch_size in cell [23]**~~\r\n",
        "- ~~**change epochs in cell [23]**~~\r\n",
        "- ~~**change importing image in cell [5]**~~\r\n",
        "- ~~import all train images and train~~\r\n",
        "- ~~import test images and fit~~\r\n",
        "- ~~export csv with test image results~~\r\n",
        "- data augmentation\r\n",
        "- train test split\r\n",
        "- try dropouts\r\n",
        "- try reducing the complexity\r\n",
        "- try AvgPooling\r\n",
        "- try managing memory with `del`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bun-jUVKRNuv"
      },
      "source": [
        "```# resize data for deep learning \r\n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\r\n",
        "y_train = np.array(y_train)\r\n",
        "\r\n",
        "x_val = x_val.reshape(-1, img_size, img_size, 1)\r\n",
        "y_val = np.array(y_val)\r\n",
        "\r\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\r\n",
        "y_test = np.array(y_test)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owCSASJ3Rbk5"
      },
      "source": [
        "For the data augmentation, i choosed to :\r\n",
        "\r\n",
        "- Randomly rotate some training images by 30 degrees\r\n",
        "- Randomly Zoom by 20% some training images\r\n",
        "- Randomly shift images horizontally by 10% of the width\r\n",
        "- Randomly shift images vertically by 10% of the height\r\n",
        "- Randomly flip images horizontally. Once our model is ready, we fit the training dataset\r\n",
        "```\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "        samplewise_center=False,  # set each sample mean to 0\r\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "        zca_whitening=False,  # apply ZCA whitening\r\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "        zoom_range = 0.2, # Randomly zoom image \r\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n",
        "        horizontal_flip = True,  # randomly flip images\r\n",
        "        vertical_flip=False)  # randomly flip images\r\n",
        "```\r\n",
        "```\r\n",
        "datagen.fit(x_train)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST5bPH8F3BfM",
        "outputId": "6605e2b0-a844-4714-bbe0-3f29d8f0636e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import time\r\n",
        "from numpy.linalg import inv, norm\r\n",
        "from IPython.display import display \r\n",
        "import pandas\r\n",
        "\r\n",
        "\r\n",
        "drive.mount(\"/content/drive\")\r\n",
        "os.chdir('/content/drive/MyDrive/Xrays/')\r\n",
        "print('\\n',os.getcwd())\r\n",
        "print(\"\\n\")\r\n",
        "print(os.listdir())\r\n",
        "\r\n",
        "save_dir = os.path.join(os.getcwd(),'saved_models')\r\n",
        "\r\n",
        "##Imports for the Learning and the plotting\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Concatenate, \\\r\n",
        "                                    AveragePooling2D, Input, Flatten, MaxPooling2D\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "\r\n",
        "\r\n",
        "##Import for preprocessing\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            " /content/drive/MyDrive/Xrays\n",
            "\n",
            "\n",
            "['labels_train.csv', 'sample_submission.csv', 'labels_train.xlsx', 'train_images', 'saved_models', 'model.png', 'test_images', 'submission_file_herck.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbvCbbLZ3R0r"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "def resize(image_pil, width, height):\r\n",
        "    '''\r\n",
        "    Resize PIL image keeping ratio and using white background.\r\n",
        "    '''\r\n",
        "    ratio_w = width / image_pil.width\r\n",
        "    ratio_h = height / image_pil.height\r\n",
        "    if ratio_w < ratio_h:\r\n",
        "        # It must be fixed by width\r\n",
        "        resize_width = width\r\n",
        "        resize_height = round(ratio_w * image_pil.height)\r\n",
        "    else:\r\n",
        "        # Fixed by height\r\n",
        "        resize_width = round(ratio_h * image_pil.width)\r\n",
        "        resize_height = height\r\n",
        "    image_resize = image_pil.resize((resize_width, resize_height), Image.ANTIALIAS)\r\n",
        "    background = Image.new('RGBA', (width, height), (0, 0, 0, 255))\r\n",
        "    offset = (round((width - resize_width) / 2), round((height - resize_height) / 2))\r\n",
        "    background.paste(image_resize, offset)\r\n",
        "    return background.convert('RGB')\r\n",
        "\r\n",
        "width = height = 270"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX3g603hDaop",
        "outputId": "2891a5db-f5ce-467d-989d-5db0da5359f3"
      },
      "source": [
        "data= pandas.read_csv('/content/drive/MyDrive/Xrays/labels_train.csv', header=None, usecols=[0,1], names=['file_name', 'class_id'])\r\n",
        "#print(labels[1:])\r\n",
        "labels = data['class_id'].values\r\n",
        "labels = labels[1:]\r\n",
        "img_name = data['file_name'].values\r\n",
        "img_name = img_name[1:]\r\n",
        "\r\n",
        "#data_labels = np.array(data[1:])\r\n",
        "#print(data_labels.shape)   \r\n",
        "\r\n",
        "labels = np.array(labels)\r\n",
        "print(labels.shape)   \r\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4672,)\n",
            "['1' '2' '2' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCva8pf_c3jx",
        "outputId": "bb7fb908-e4bb-45a8-cb68-0ec3e5438c67"
      },
      "source": [
        "train_imgs = []\r\n",
        "for i in range(img_name.size):\r\n",
        "  img = Image.open('/content/drive/MyDrive/Xrays/train_images/{train_image}'.format(train_image=img_name[i]))\r\n",
        "  train_imgs.append(img)\r\n",
        "\r\n",
        "print(\"Loaded Training data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Training data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV4NREswYRyf"
      },
      "source": [
        "for i in range(img_name.size):\r\n",
        "  train_imgs[i]= resize(train_imgs[i], width, height)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7OLn8SdfHHx"
      },
      "source": [
        "for i in range(img_name.size):\r\n",
        "  train_imgs[i]= np.asarray(train_imgs[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e22nwXUVgUy6",
        "outputId": "925eb59a-6d4b-4821-be58-6889b26e0238"
      },
      "source": [
        "train_imgs = np.array(train_imgs, dtype=\"float32\")/255.0\r\n",
        "\r\n",
        "print(train_imgs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4672, 270, 270, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbZC01ZN8UGU",
        "outputId": "f38ed4ff-0c49-4a61-cf9f-e5d3b2cdae53"
      },
      "source": [
        "depth = 8\r\n",
        "\r\n",
        "#x_train = train_imgs[:2803]\r\n",
        "#y_train = labels[:2803]\r\n",
        "#x_test = train_imgs[2803:]\r\n",
        "#y_test = labels[2803:]\r\n",
        "num_classes = 3\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_imgs,labels, test_size=0.15)\r\n",
        "\r\n",
        "input_shape = x_train.shape[1:]\r\n",
        "\r\n",
        "x_train_mean = np.mean(x_train, axis=0)\r\n",
        "x_train -= x_train_mean\r\n",
        "x_test -= x_train_mean\r\n",
        "\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "\r\n",
        "t_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "t_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "print('y_train (labels) shape:', y_train.shape)\r\n",
        "print('t_train (one-hot rep) shape:', t_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (3737, 270, 270, 3)\n",
            "3737 train samples\n",
            "935 test samples\n",
            "y_train (labels) shape: (3737,)\n",
            "t_train (one-hot rep) shape: (3737, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0VZB6i-Z_ih",
        "outputId": "0c5a7cee-071c-4775-e773-350bc9d75509"
      },
      "source": [
        "print(y_test)\r\n",
        "print(t_test)\r\n",
        "print(y_train)\r\n",
        "print(t_train)\r\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '2' '0' ... '1' '1' '1']\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n",
            "['1' '2' '2' ... '1' '1' '1']\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n",
            "(256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_RW3XLc0z8Q"
      },
      "source": [
        "#Idk which one works \r\n",
        "train_imgs = []\r\n",
        "train_imgs = None\r\n",
        "del train_imgs\r\n",
        "labels = []\r\n",
        "labels = None\r\n",
        "del labels\r\n",
        "\r\n",
        "y_test = []\r\n",
        "y_test = None\r\n",
        "del y_test\r\n",
        "\r\n",
        "y_train = []\r\n",
        "y_train = None\r\n",
        "del y_train\r\n",
        "\r\n",
        "#Trying to release memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksB30HrvWXFb"
      },
      "source": [
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True):\r\n",
        "    conv = Conv2D(num_filters,\r\n",
        "                  kernel_size=kernel_size,\r\n",
        "                  strides=strides,\r\n",
        "                  padding='same',\r\n",
        "                  kernel_initializer='he_normal',\r\n",
        "                  kernel_regularizer=l2(1e-4))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAUYakbsWjKJ"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=3):\r\n",
        "    if (depth - 2) % 6 != 0:\r\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs)\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             strides=strides)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             activation=None)\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters,\r\n",
        "                                 kernel_size=2, ### originally: 1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "            \r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    print('Model parameters: {:d}'.format(model.count_params()))\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jCC3ta_XDwD"
      },
      "source": [
        "def lr_schedule(epoch):\r\n",
        "  lr = 1e-3\r\n",
        "  if (epoch>180) :\r\n",
        "      lr *= 0.5e-3\r\n",
        "  elif epoch > 160:\r\n",
        "      lr *= 1e-3\r\n",
        "  elif epoch > 120:\r\n",
        "      lr *= 1e-2\r\n",
        "  elif epoch > 80:\r\n",
        "      lr *= 1e-1\r\n",
        "  return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTIqCW5XXbMj"
      },
      "source": [
        "class MyCallback(keras.callbacks.Callback):\r\n",
        "    tstart = None\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_train_end(self, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_epoch_begin(self, epoch, logs={}):\r\n",
        "        self.tstart = time.time()\r\n",
        "        print('epoch:{:03d}'.format(epoch+1), end=', ')\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        print('loss:{:8.6f}, acc:{:8.6f},  val_loss:{:8.6f}, val_acc:{:8.6f},  val_acc-acc = {:5.2f}%,  lr:{:0.6f}  [{:0.2f} sec]'.format(\r\n",
        "                logs.get('loss'), logs.get('acc'),\r\n",
        "                logs.get('val_loss'), logs.get('val_acc'),\r\n",
        "                100*(logs.get('val_acc')-logs.get('acc')),\r\n",
        "                K.eval(self.model.optimizer.lr),\r\n",
        "                time.time()-self.tstart))\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_batch_begin(self, batch, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_batch_end(self, batch, logs={}):\r\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvh5AxtvXi3C"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)\r\n",
        "    \r\n",
        "model.compile(loss=\"categorical_crossentropy\",\r\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\r\n",
        "              metrics=['acc'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67on7ovvYJnR"
      },
      "source": [
        "plot_model(model, show_shapes=True, dpi=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgSMdRbWYVyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a63dac-e139-4976-eb58-fc1dea574749"
      },
      "source": [
        "# Training parameters\r\n",
        "batch_size = 32  # orig paper trained all networks with batch_size=128\r\n",
        "epochs = 200\r\n",
        "\r\n",
        "# Prepare model model saving directory.\r\n",
        "model_name = 'resnet8-e{epoch:04d}-loss{loss:.3f}-acc{acc:.3f}-valloss{val_loss:.3f}-valacc{val_acc:.3f}.h5'\r\n",
        "if not os.path.isdir(save_dir):\r\n",
        "    os.makedirs(save_dir)\r\n",
        "filepath = os.path.join(save_dir, model_name)\r\n",
        "\r\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\r\n",
        "                             monitor='val_acc',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "\r\n",
        "# This will do preprocessing and realtime data augmentation:\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    # set input mean to 0 over the dataset\r\n",
        "    featurewise_center=False,\r\n",
        "    # set each sample mean to 0\r\n",
        "    samplewise_center=False,\r\n",
        "    # divide inputs by std of dataset\r\n",
        "    featurewise_std_normalization=False,\r\n",
        "    # divide each input by its std\r\n",
        "    samplewise_std_normalization=False,\r\n",
        "    # apply ZCA whitening\r\n",
        "    zca_whitening=False,\r\n",
        "    # epsilon for ZCA whitening\r\n",
        "    zca_epsilon=1e-06,\r\n",
        "    # randomly rotate images in the range (deg 0 to 180)\r\n",
        "    rotation_range=0,\r\n",
        "    # randomly shift images horizontally\r\n",
        "    width_shift_range=0.1,\r\n",
        "    # randomly shift images vertically\r\n",
        "    height_shift_range=0.1,\r\n",
        "    # set range for random shear                                                  ## dew it\r\n",
        "    shear_range=0.,\r\n",
        "    # set range for random zoom\r\n",
        "    zoom_range=0.,\r\n",
        "    # set range for random channel shifts\r\n",
        "    channel_shift_range=0.,\r\n",
        "    # set mode for filling points outside the input boundaries\r\n",
        "    fill_mode='nearest',\r\n",
        "    # value used for fill_mode = \"constant\"\r\n",
        "    cval=0.,\r\n",
        "    # randomly flip images\r\n",
        "    horizontal_flip=True,\r\n",
        "    # randomly flip images\r\n",
        "    vertical_flip=False,\r\n",
        "    # set rescaling factor (applied before any other transformation)              ##dew it\r\n",
        "    rescale=None,\r\n",
        "    # set function that will be applied on each input\r\n",
        "    preprocessing_function=None,\r\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\r\n",
        "    data_format=None,\r\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\r\n",
        "    validation_split=0.0)\r\n",
        "\r\n",
        "# Compute quantities required for featurewise normalization\r\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "datagen.fit(x_train)\r\n",
        "\r\n",
        "\r\n",
        "# Fit the model on the batches generated by datagen.flow().\r\n",
        "history = model.fit(datagen.flow(x_train, t_train, batch_size=batch_size), \r\n",
        "                    validation_data=(x_test, t_test), epochs=epochs, verbose=0, \r\n",
        "                    workers=4, steps_per_epoch = int(x_train.shape[0]/batch_size), \r\n",
        "                    callbacks=[lr_reducer, lr_scheduler, MyCallback(), checkpoint])\r\n",
        "\r\n",
        "# Score trained model.\r\n",
        "scores = model.evaluate(x_test, t_test, verbose=1)\r\n",
        "print('Test loss:', scores[0])\r\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:001, loss:1.243607, acc:0.616464,  val_loss:0.766715, val_acc:0.686631,  val_acc-acc =  7.02%,  lr:0.001000  [53.65 sec]\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.68663, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0001-loss1.244-acc0.616-valloss0.767-valacc0.687.h5\n",
            "epoch:002, loss:0.770316, acc:0.700405,  val_loss:0.747147, val_acc:0.658824,  val_acc-acc = -4.16%,  lr:0.001000  [47.97 sec]\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.68663\n",
            "epoch:003, loss:0.710343, acc:0.725506,  val_loss:0.731731, val_acc:0.698396,  val_acc-acc = -2.71%,  lr:0.001000  [47.91 sec]\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.68663 to 0.69840, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0003-loss0.710-acc0.726-valloss0.732-valacc0.698.h5\n",
            "epoch:004, loss:0.690686, acc:0.730364,  val_loss:0.570896, val_acc:0.792513,  val_acc-acc =  6.21%,  lr:0.001000  [48.09 sec]\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.69840 to 0.79251, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0004-loss0.691-acc0.730-valloss0.571-valacc0.793.h5\n",
            "epoch:005, loss:0.660909, acc:0.748718,  val_loss:0.643414, val_acc:0.761497,  val_acc-acc =  1.28%,  lr:0.001000  [48.05 sec]\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.79251\n",
            "epoch:006, loss:0.645643, acc:0.745479,  val_loss:1.005374, val_acc:0.682353,  val_acc-acc = -6.31%,  lr:0.001000  [48.41 sec]\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79251\n",
            "epoch:007, loss:0.649882, acc:0.755466,  val_loss:0.607755, val_acc:0.776471,  val_acc-acc =  2.10%,  lr:0.001000  [47.92 sec]\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79251\n",
            "epoch:008, loss:0.618071, acc:0.767072,  val_loss:0.601658, val_acc:0.774332,  val_acc-acc =  0.73%,  lr:0.001000  [47.96 sec]\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79251\n",
            "epoch:009, loss:0.634212, acc:0.758704,  val_loss:0.553952, val_acc:0.802139,  val_acc-acc =  4.34%,  lr:0.001000  [48.08 sec]\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.79251 to 0.80214, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0009-loss0.634-acc0.759-valloss0.554-valacc0.802.h5\n",
            "epoch:010, loss:0.596682, acc:0.779217,  val_loss:0.599049, val_acc:0.767914,  val_acc-acc = -1.13%,  lr:0.001000  [48.30 sec]\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80214\n",
            "epoch:011, loss:0.622865, acc:0.766262,  val_loss:0.581074, val_acc:0.768984,  val_acc-acc =  0.27%,  lr:0.001000  [47.98 sec]\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80214\n",
            "epoch:012, loss:0.613259, acc:0.771120,  val_loss:0.542811, val_acc:0.795722,  val_acc-acc =  2.46%,  lr:0.001000  [48.33 sec]\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80214\n",
            "epoch:013, loss:0.602384, acc:0.773009,  val_loss:0.557181, val_acc:0.797861,  val_acc-acc =  2.49%,  lr:0.001000  [48.15 sec]\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80214\n",
            "epoch:014, loss:0.607299, acc:0.773549,  val_loss:0.535776, val_acc:0.806417,  val_acc-acc =  3.29%,  lr:0.001000  [48.08 sec]\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.80214 to 0.80642, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0014-loss0.607-acc0.774-valloss0.536-valacc0.806.h5\n",
            "epoch:015, loss:0.586425, acc:0.781646,  val_loss:0.634052, val_acc:0.765775,  val_acc-acc = -1.59%,  lr:0.001000  [48.04 sec]\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80642\n",
            "epoch:016, loss:0.574878, acc:0.783536,  val_loss:0.599050, val_acc:0.750802,  val_acc-acc = -3.27%,  lr:0.001000  [48.25 sec]\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80642\n",
            "epoch:017, loss:0.570141, acc:0.785425,  val_loss:0.533288, val_acc:0.791444,  val_acc-acc =  0.60%,  lr:0.001000  [47.77 sec]\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80642\n",
            "epoch:018, loss:0.582739, acc:0.778408,  val_loss:0.543711, val_acc:0.797861,  val_acc-acc =  1.95%,  lr:0.001000  [48.27 sec]\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80642\n",
            "epoch:019, loss:0.575421, acc:0.781377,  val_loss:0.531715, val_acc:0.804278,  val_acc-acc =  2.29%,  lr:0.001000  [48.06 sec]\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80642\n",
            "epoch:020, loss:0.578360, acc:0.783266,  val_loss:0.562559, val_acc:0.773262,  val_acc-acc = -1.00%,  lr:0.001000  [47.78 sec]\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80642\n",
            "epoch:021, loss:0.560724, acc:0.791903,  val_loss:0.532699, val_acc:0.812834,  val_acc-acc =  2.09%,  lr:0.001000  [47.79 sec]\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.80642 to 0.81283, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0021-loss0.561-acc0.792-valloss0.533-valacc0.813.h5\n",
            "epoch:022, loss:0.567192, acc:0.787314,  val_loss:0.577785, val_acc:0.786096,  val_acc-acc = -0.12%,  lr:0.001000  [47.97 sec]\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.81283\n",
            "epoch:023, loss:0.576556, acc:0.783536,  val_loss:0.701863, val_acc:0.744385,  val_acc-acc = -3.92%,  lr:0.001000  [48.00 sec]\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.81283\n",
            "epoch:024, loss:0.570194, acc:0.788124,  val_loss:0.620495, val_acc:0.757219,  val_acc-acc = -3.09%,  lr:0.000316  [48.23 sec]\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.81283\n",
            "epoch:025, loss:0.565682, acc:0.787584,  val_loss:0.546057, val_acc:0.790374,  val_acc-acc =  0.28%,  lr:0.001000  [48.00 sec]\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.81283\n",
            "epoch:026, loss:0.546951, acc:0.796761,  val_loss:0.531934, val_acc:0.803209,  val_acc-acc =  0.64%,  lr:0.001000  [47.94 sec]\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.81283\n",
            "epoch:027, loss:0.551602, acc:0.795951,  val_loss:0.574755, val_acc:0.787166,  val_acc-acc = -0.88%,  lr:0.001000  [47.95 sec]\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.81283\n",
            "epoch:028, loss:0.553287, acc:0.793792,  val_loss:0.541293, val_acc:0.790374,  val_acc-acc = -0.34%,  lr:0.001000  [48.03 sec]\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.81283\n",
            "epoch:029, loss:0.557282, acc:0.795412,  val_loss:0.547715, val_acc:0.797861,  val_acc-acc =  0.24%,  lr:0.000316  [48.10 sec]\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.81283\n",
            "epoch:030, loss:0.547014, acc:0.795682,  val_loss:0.524232, val_acc:0.804278,  val_acc-acc =  0.86%,  lr:0.001000  [47.82 sec]\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.81283\n",
            "epoch:031, loss:0.551962, acc:0.787314,  val_loss:0.526429, val_acc:0.809626,  val_acc-acc =  2.23%,  lr:0.001000  [48.35 sec]\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.81283\n",
            "epoch:032, loss:0.544944, acc:0.794062,  val_loss:0.529793, val_acc:0.793583,  val_acc-acc = -0.05%,  lr:0.001000  [48.07 sec]\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.81283\n",
            "epoch:033, loss:0.545993, acc:0.793252,  val_loss:0.519521, val_acc:0.805348,  val_acc-acc =  1.21%,  lr:0.001000  [48.14 sec]\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.81283\n",
            "epoch:034, loss:0.540102, acc:0.792443,  val_loss:0.527317, val_acc:0.801069,  val_acc-acc =  0.86%,  lr:0.001000  [48.01 sec]\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.81283\n",
            "epoch:035, loss:0.545580, acc:0.789744,  val_loss:0.528877, val_acc:0.788235,  val_acc-acc = -0.15%,  lr:0.001000  [48.09 sec]\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.81283\n",
            "epoch:036, loss:0.533527, acc:0.795142,  val_loss:0.560820, val_acc:0.791444,  val_acc-acc = -0.37%,  lr:0.001000  [47.95 sec]\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.81283\n",
            "epoch:037, loss:0.537163, acc:0.795142,  val_loss:0.530126, val_acc:0.793583,  val_acc-acc = -0.16%,  lr:0.001000  [47.89 sec]\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.81283\n",
            "epoch:038, loss:0.535219, acc:0.798650,  val_loss:0.548373, val_acc:0.793583,  val_acc-acc = -0.51%,  lr:0.000316  [48.01 sec]\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.81283\n",
            "epoch:039, loss:0.535060, acc:0.794332,  val_loss:0.513023, val_acc:0.793583,  val_acc-acc = -0.07%,  lr:0.001000  [47.82 sec]\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.81283\n",
            "epoch:040, loss:0.531810, acc:0.794872,  val_loss:0.568227, val_acc:0.786096,  val_acc-acc = -0.88%,  lr:0.001000  [47.86 sec]\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.81283\n",
            "epoch:041, loss:0.516139, acc:0.806748,  val_loss:0.545383, val_acc:0.798930,  val_acc-acc = -0.78%,  lr:0.001000  [47.83 sec]\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.81283\n",
            "epoch:042, loss:0.522826, acc:0.799460,  val_loss:0.536466, val_acc:0.790374,  val_acc-acc = -0.91%,  lr:0.001000  [47.77 sec]\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.81283\n",
            "epoch:043, loss:0.527824, acc:0.794062,  val_loss:0.576312, val_acc:0.794652,  val_acc-acc =  0.06%,  lr:0.001000  [47.90 sec]\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.81283\n",
            "epoch:044, loss:0.504657, acc:0.812686,  val_loss:0.561740, val_acc:0.776471,  val_acc-acc = -3.62%,  lr:0.000316  [48.25 sec]\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.81283\n",
            "epoch:045, loss:0.510272, acc:0.804588,  val_loss:0.542987, val_acc:0.787166,  val_acc-acc = -1.74%,  lr:0.001000  [47.96 sec]\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.81283\n",
            "epoch:046, loss:0.517443, acc:0.798650,  val_loss:0.507753, val_acc:0.809626,  val_acc-acc =  1.10%,  lr:0.001000  [47.98 sec]\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.81283\n",
            "epoch:047, loss:0.520474, acc:0.804588,  val_loss:0.549612, val_acc:0.797861,  val_acc-acc = -0.67%,  lr:0.001000  [47.95 sec]\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.81283\n",
            "epoch:048, loss:0.525450, acc:0.794062,  val_loss:0.508743, val_acc:0.795722,  val_acc-acc =  0.17%,  lr:0.001000  [47.93 sec]\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.81283\n",
            "epoch:049, loss:0.514894, acc:0.799460,  val_loss:0.515843, val_acc:0.806417,  val_acc-acc =  0.70%,  lr:0.001000  [47.88 sec]\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.81283\n",
            "epoch:050, loss:0.511881, acc:0.809987,  val_loss:0.519397, val_acc:0.809626,  val_acc-acc = -0.04%,  lr:0.001000  [47.85 sec]\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.81283\n",
            "epoch:051, loss:0.513615, acc:0.796761,  val_loss:0.511024, val_acc:0.809626,  val_acc-acc =  1.29%,  lr:0.000316  [48.31 sec]\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.81283\n",
            "epoch:052, loss:0.505990, acc:0.806748,  val_loss:0.518951, val_acc:0.809626,  val_acc-acc =  0.29%,  lr:0.001000  [47.87 sec]\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.81283\n",
            "epoch:053, loss:0.514967, acc:0.804588,  val_loss:0.509916, val_acc:0.807487,  val_acc-acc =  0.29%,  lr:0.001000  [47.92 sec]\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.81283\n",
            "epoch:054, loss:0.498609, acc:0.808367,  val_loss:0.541221, val_acc:0.780749,  val_acc-acc = -2.76%,  lr:0.001000  [47.89 sec]\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.81283\n",
            "epoch:055, loss:0.513998, acc:0.800000,  val_loss:0.533127, val_acc:0.807487,  val_acc-acc =  0.75%,  lr:0.001000  [47.87 sec]\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.81283\n",
            "epoch:056, loss:0.492999, acc:0.813765,  val_loss:0.509276, val_acc:0.798930,  val_acc-acc = -1.48%,  lr:0.000316  [48.09 sec]\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.81283\n",
            "epoch:057, loss:0.483328, acc:0.817274,  val_loss:0.506105, val_acc:0.803209,  val_acc-acc = -1.41%,  lr:0.001000  [48.14 sec]\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.81283\n",
            "epoch:058, loss:0.504003, acc:0.809717,  val_loss:0.548386, val_acc:0.814973,  val_acc-acc =  0.53%,  lr:0.001000  [47.82 sec]\n",
            "\n",
            "Epoch 00058: val_acc improved from 0.81283 to 0.81497, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0058-loss0.504-acc0.810-valloss0.548-valacc0.815.h5\n",
            "epoch:059, loss:0.491544, acc:0.815115,  val_loss:0.520339, val_acc:0.791444,  val_acc-acc = -2.37%,  lr:0.001000  [48.00 sec]\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.81497\n",
            "epoch:060, loss:0.497044, acc:0.814305,  val_loss:0.499741, val_acc:0.801069,  val_acc-acc = -1.32%,  lr:0.001000  [47.97 sec]\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.81497\n",
            "epoch:061, loss:0.499098, acc:0.806208,  val_loss:0.512084, val_acc:0.791444,  val_acc-acc = -1.48%,  lr:0.001000  [48.07 sec]\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.81497\n",
            "epoch:062, loss:0.490052, acc:0.809447,  val_loss:0.564136, val_acc:0.774332,  val_acc-acc = -3.51%,  lr:0.001000  [47.75 sec]\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.81497\n",
            "epoch:063, loss:0.476493, acc:0.817004,  val_loss:0.563890, val_acc:0.777540,  val_acc-acc = -3.95%,  lr:0.001000  [48.01 sec]\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.81497\n",
            "epoch:064, loss:0.493072, acc:0.809987,  val_loss:0.537805, val_acc:0.795722,  val_acc-acc = -1.43%,  lr:0.001000  [48.03 sec]\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.81497\n",
            "epoch:065, loss:0.490600, acc:0.813495,  val_loss:0.532009, val_acc:0.794652,  val_acc-acc = -1.88%,  lr:0.000316  [47.95 sec]\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.81497\n",
            "epoch:066, loss:0.483280, acc:0.816734,  val_loss:0.525102, val_acc:0.780749,  val_acc-acc = -3.60%,  lr:0.001000  [47.98 sec]\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.81497\n",
            "epoch:067, loss:0.498214, acc:0.804588,  val_loss:0.515872, val_acc:0.792513,  val_acc-acc = -1.21%,  lr:0.001000  [47.83 sec]\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.81497\n",
            "epoch:068, loss:0.482955, acc:0.820783,  val_loss:0.559936, val_acc:0.791444,  val_acc-acc = -2.93%,  lr:0.001000  [48.11 sec]\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.81497\n",
            "epoch:069, loss:0.477799, acc:0.819703,  val_loss:0.510278, val_acc:0.796791,  val_acc-acc = -2.29%,  lr:0.001000  [47.77 sec]\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.81497\n",
            "epoch:070, loss:0.487153, acc:0.816734,  val_loss:0.504313, val_acc:0.805348,  val_acc-acc = -1.14%,  lr:0.000316  [48.30 sec]\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.81497\n",
            "epoch:071, loss:0.479334, acc:0.813765,  val_loss:0.496479, val_acc:0.803209,  val_acc-acc = -1.06%,  lr:0.001000  [47.88 sec]\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.81497\n",
            "epoch:072, loss:0.476327, acc:0.812955,  val_loss:0.516866, val_acc:0.792513,  val_acc-acc = -2.04%,  lr:0.001000  [48.08 sec]\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.81497\n",
            "epoch:073, loss:0.488612, acc:0.812146,  val_loss:0.527836, val_acc:0.788235,  val_acc-acc = -2.39%,  lr:0.001000  [48.08 sec]\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.81497\n",
            "epoch:074, loss:0.473467, acc:0.828880,  val_loss:0.532067, val_acc:0.796791,  val_acc-acc = -3.21%,  lr:0.001000  [47.93 sec]\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.81497\n",
            "epoch:075, loss:0.469280, acc:0.822402,  val_loss:0.533604, val_acc:0.796791,  val_acc-acc = -2.56%,  lr:0.001000  [47.92 sec]\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.81497\n",
            "epoch:076, loss:0.468591, acc:0.819504,  val_loss:0.523016, val_acc:0.796791,  val_acc-acc = -2.27%,  lr:0.000316  [48.21 sec]\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.81497\n",
            "epoch:077, loss:0.469232, acc:0.814845,  val_loss:0.537472, val_acc:0.786096,  val_acc-acc = -2.87%,  lr:0.001000  [48.08 sec]\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.81497\n",
            "epoch:078, loss:0.463813, acc:0.827530,  val_loss:0.501500, val_acc:0.802139,  val_acc-acc = -2.54%,  lr:0.001000  [47.92 sec]\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.81497\n",
            "epoch:079, loss:0.463562, acc:0.815115,  val_loss:0.510248, val_acc:0.790374,  val_acc-acc = -2.47%,  lr:0.001000  [47.95 sec]\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.81497\n",
            "epoch:080, loss:0.463555, acc:0.820783,  val_loss:0.579875, val_acc:0.768984,  val_acc-acc = -5.18%,  lr:0.001000  [47.86 sec]\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.81497\n",
            "epoch:081, loss:0.463452, acc:0.821592,  val_loss:0.517175, val_acc:0.801069,  val_acc-acc = -2.05%,  lr:0.000316  [47.75 sec]\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.81497\n",
            "epoch:082, loss:0.443460, acc:0.832928,  val_loss:0.497674, val_acc:0.810695,  val_acc-acc = -2.22%,  lr:0.000100  [47.81 sec]\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.81497\n",
            "epoch:083, loss:0.431352, acc:0.842375,  val_loss:0.500790, val_acc:0.812834,  val_acc-acc = -2.95%,  lr:0.000100  [47.97 sec]\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.81497\n",
            "epoch:084, loss:0.420847, acc:0.842915,  val_loss:0.497705, val_acc:0.817112,  val_acc-acc = -2.58%,  lr:0.000100  [47.69 sec]\n",
            "\n",
            "Epoch 00084: val_acc improved from 0.81497 to 0.81711, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0084-loss0.421-acc0.843-valloss0.498-valacc0.817.h5\n",
            "epoch:085, loss:0.417851, acc:0.842375,  val_loss:0.497453, val_acc:0.807487,  val_acc-acc = -3.49%,  lr:0.000100  [47.97 sec]\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.81711\n",
            "epoch:086, loss:0.414008, acc:0.841835,  val_loss:0.497286, val_acc:0.811765,  val_acc-acc = -3.01%,  lr:0.000032  [47.86 sec]\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.81711\n",
            "epoch:087, loss:0.411124, acc:0.848043,  val_loss:0.492255, val_acc:0.818182,  val_acc-acc = -2.99%,  lr:0.000100  [47.89 sec]\n",
            "\n",
            "Epoch 00087: val_acc improved from 0.81711 to 0.81818, saving model to /content/drive/MyDrive/Xrays/saved_models/resnet44-e0087-loss0.411-acc0.848-valloss0.492-valacc0.818.h5\n",
            "epoch:088, loss:0.411602, acc:0.844265,  val_loss:0.491436, val_acc:0.818182,  val_acc-acc = -2.61%,  lr:0.000100  [47.90 sec]\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.81818\n",
            "epoch:089, loss:0.401464, acc:0.840486,  val_loss:0.493860, val_acc:0.816043,  val_acc-acc = -2.44%,  lr:0.000100  [47.75 sec]\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.81818\n",
            "epoch:090, loss:0.413175, acc:0.848043,  val_loss:0.492929, val_acc:0.817112,  val_acc-acc = -3.09%,  lr:0.000100  [48.01 sec]\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.81818\n",
            "epoch:091, loss:0.404656, acc:0.852362,  val_loss:0.487726, val_acc:0.809626,  val_acc-acc = -4.27%,  lr:0.000100  [47.84 sec]\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.81818\n",
            "epoch:092, loss:0.414715, acc:0.840756,  val_loss:0.496993, val_acc:0.809626,  val_acc-acc = -3.11%,  lr:0.000100  [47.67 sec]\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.81818\n",
            "epoch:093, loss:0.393601, acc:0.849933,  val_loss:0.493243, val_acc:0.810695,  val_acc-acc = -3.92%,  lr:0.000100  [47.80 sec]\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.81818\n",
            "epoch:094, loss:0.401781, acc:0.850742,  val_loss:0.489216, val_acc:0.810695,  val_acc-acc = -4.00%,  lr:0.000100  [47.81 sec]\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.81818\n",
            "epoch:095, loss:0.410359, acc:0.849123,  val_loss:0.487966, val_acc:0.810695,  val_acc-acc = -3.84%,  lr:0.000100  [47.78 sec]\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.81818\n",
            "epoch:096, loss:0.399814, acc:0.852901,  val_loss:0.496841, val_acc:0.807487,  val_acc-acc = -4.54%,  lr:0.000032  [47.77 sec]\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.81818\n",
            "epoch:097, loss:0.392322, acc:0.848313,  val_loss:0.492904, val_acc:0.808556,  val_acc-acc = -3.98%,  lr:0.000100  [47.97 sec]\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.81818\n",
            "epoch:098, loss:0.396550, acc:0.855061,  val_loss:0.497847, val_acc:0.810695,  val_acc-acc = -4.44%,  lr:0.000100  [47.71 sec]\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.81818\n",
            "epoch:099, loss:0.402437, acc:0.845344,  val_loss:0.492687, val_acc:0.807487,  val_acc-acc = -3.79%,  lr:0.000100  [47.70 sec]\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.81818\n",
            "epoch:100, loss:0.393743, acc:0.851282,  val_loss:0.496128, val_acc:0.814973,  val_acc-acc = -3.63%,  lr:0.000100  [47.95 sec]\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.81818\n",
            "epoch:101, loss:0.398704, acc:0.852632,  val_loss:0.496989, val_acc:0.812834,  val_acc-acc = -3.98%,  lr:0.000032  [47.79 sec]\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.81818\n",
            "epoch:102, loss:0.380768, acc:0.860459,  val_loss:0.496219, val_acc:0.817112,  val_acc-acc = -4.33%,  lr:0.000100  [47.75 sec]\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.81818\n",
            "epoch:103, loss:0.387476, acc:0.849663,  val_loss:0.495240, val_acc:0.804278,  val_acc-acc = -4.54%,  lr:0.000100  [47.88 sec]\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.81818\n",
            "epoch:104, loss:0.386342, acc:0.855601,  val_loss:0.495072, val_acc:0.812834,  val_acc-acc = -4.28%,  lr:0.000100  [47.87 sec]\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.81818\n",
            "epoch:105, loss:0.387112, acc:0.854521,  val_loss:0.494760, val_acc:0.801069,  val_acc-acc = -5.35%,  lr:0.000100  [47.84 sec]\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.81818\n",
            "epoch:106, loss:0.394599, acc:0.848853,  val_loss:0.498244, val_acc:0.802139,  val_acc-acc = -4.67%,  lr:0.000032  [47.72 sec]\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.81818\n",
            "epoch:107, loss:0.382006, acc:0.860189,  val_loss:0.501199, val_acc:0.804278,  val_acc-acc = -5.59%,  lr:0.000100  [47.91 sec]\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.81818\n",
            "epoch:108, loss:0.391983, acc:0.849393,  val_loss:0.499441, val_acc:0.802139,  val_acc-acc = -4.73%,  lr:0.000100  [47.83 sec]\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.81818\n",
            "epoch:109, loss:0.383519, acc:0.859379,  val_loss:0.501379, val_acc:0.801069,  val_acc-acc = -5.83%,  lr:0.000100  [48.01 sec]\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.81818\n",
            "epoch:110, loss:0.388802, acc:0.853981,  val_loss:0.499898, val_acc:0.798930,  val_acc-acc = -5.51%,  lr:0.000100  [47.79 sec]\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.81818\n",
            "epoch:111, loss:0.375131, acc:0.857490,  val_loss:0.501600, val_acc:0.797861,  val_acc-acc = -5.96%,  lr:0.000032  [47.76 sec]\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.81818\n",
            "epoch:112, loss:0.380856, acc:0.853981,  val_loss:0.502337, val_acc:0.800000,  val_acc-acc = -5.40%,  lr:0.000100  [47.82 sec]\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.81818\n",
            "epoch:113, loss:0.381180, acc:0.858839,  val_loss:0.509073, val_acc:0.796791,  val_acc-acc = -6.20%,  lr:0.000100  [47.69 sec]\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.81818\n",
            "epoch:114, loss:0.367104, acc:0.858839,  val_loss:0.499616, val_acc:0.806417,  val_acc-acc = -5.24%,  lr:0.000100  [47.77 sec]\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.81818\n",
            "epoch:115, loss:0.387806, acc:0.855601,  val_loss:0.501471, val_acc:0.796791,  val_acc-acc = -5.88%,  lr:0.000100  [47.75 sec]\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.81818\n",
            "epoch:116, loss:0.380742, acc:0.860729,  val_loss:0.505466, val_acc:0.796791,  val_acc-acc = -6.39%,  lr:0.000032  [48.09 sec]\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.81818\n",
            "epoch:117, loss:0.378453, acc:0.859379,  val_loss:0.498836, val_acc:0.798930,  val_acc-acc = -6.04%,  lr:0.000100  [47.90 sec]\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.81818\n",
            "epoch:118, loss:0.381019, acc:0.856680,  val_loss:0.497341, val_acc:0.797861,  val_acc-acc = -5.88%,  lr:0.000100  [47.74 sec]\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.81818\n",
            "epoch:119, loss:0.383455, acc:0.857220,  val_loss:0.497032, val_acc:0.804278,  val_acc-acc = -5.29%,  lr:0.000100  [47.71 sec]\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.81818\n",
            "epoch:120, loss:0.379577, acc:0.857220,  val_loss:0.503240, val_acc:0.802139,  val_acc-acc = -5.51%,  lr:0.000100  [47.86 sec]\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.81818\n",
            "epoch:121, loss:0.373310, acc:0.858839,  val_loss:0.503294, val_acc:0.803209,  val_acc-acc = -5.56%,  lr:0.000032  [47.97 sec]\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.81818\n",
            "epoch:122, loss:0.372726, acc:0.858300,  val_loss:0.502097, val_acc:0.805348,  val_acc-acc = -5.30%,  lr:0.000010  [48.06 sec]\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.81818\n",
            "epoch:123, loss:0.376965, acc:0.859919,  val_loss:0.502803, val_acc:0.802139,  val_acc-acc = -5.78%,  lr:0.000010  [47.83 sec]\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.81818\n",
            "epoch:124, loss:0.361484, acc:0.865047,  val_loss:0.502015, val_acc:0.801069,  val_acc-acc = -6.40%,  lr:0.000010  [47.74 sec]\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.81818\n",
            "epoch:125, loss:0.375569, acc:0.864237,  val_loss:0.501302, val_acc:0.803209,  val_acc-acc = -6.10%,  lr:0.000010  [47.77 sec]\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.81818\n",
            "epoch:126, loss:0.371268, acc:0.858839,  val_loss:0.501248, val_acc:0.801069,  val_acc-acc = -5.78%,  lr:0.000003  [47.71 sec]\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.81818\n",
            "epoch:127, loss:0.377912, acc:0.853441,  val_loss:0.500719, val_acc:0.801069,  val_acc-acc = -5.24%,  lr:0.000010  [47.94 sec]\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.81818\n",
            "epoch:128, loss:0.377895, acc:0.859649,  val_loss:0.500112, val_acc:0.800000,  val_acc-acc = -5.96%,  lr:0.000010  [47.84 sec]\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.81818\n",
            "epoch:129, loss:0.380510, acc:0.864237,  val_loss:0.500562, val_acc:0.800000,  val_acc-acc = -6.42%,  lr:0.000010  [47.84 sec]\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.81818\n",
            "epoch:130, loss:0.362770, acc:0.864507,  val_loss:0.499906, val_acc:0.801069,  val_acc-acc = -6.34%,  lr:0.000010  [47.70 sec]\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.81818\n",
            "epoch:131, loss:0.367651, acc:0.859109,  val_loss:0.499973, val_acc:0.802139,  val_acc-acc = -5.70%,  lr:0.000003  [47.76 sec]\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.81818\n",
            "epoch:132, loss:0.368277, acc:0.864777,  val_loss:0.499844, val_acc:0.802139,  val_acc-acc = -6.26%,  lr:0.000010  [47.93 sec]\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.81818\n",
            "epoch:133, loss:0.359270, acc:0.863428,  val_loss:0.499716, val_acc:0.802139,  val_acc-acc = -6.13%,  lr:0.000010  [47.92 sec]\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.81818\n",
            "epoch:134, loss:0.364941, acc:0.865317,  val_loss:0.498789, val_acc:0.801069,  val_acc-acc = -6.42%,  lr:0.000010  [47.76 sec]\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.81818\n",
            "epoch:135, loss:0.363677, acc:0.871255,  val_loss:0.498795, val_acc:0.800000,  val_acc-acc = -7.13%,  lr:0.000010  [48.22 sec]\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.81818\n",
            "epoch:136, loss:0.363517, acc:0.863428,  val_loss:0.498906, val_acc:0.798930,  val_acc-acc = -6.45%,  lr:0.000003  [47.67 sec]\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.81818\n",
            "epoch:137, loss:0.364888, acc:0.868016,  val_loss:0.499085, val_acc:0.797861,  val_acc-acc = -7.02%,  lr:0.000010  [47.73 sec]\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.81818\n",
            "epoch:138, loss:0.370957, acc:0.862618,  val_loss:0.499079, val_acc:0.796791,  val_acc-acc = -6.58%,  lr:0.000010  [47.75 sec]\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.81818\n",
            "epoch:139, loss:0.362044, acc:0.859109,  val_loss:0.498717, val_acc:0.798930,  val_acc-acc = -6.02%,  lr:0.000010  [47.86 sec]\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.81818\n",
            "epoch:140, loss:0.370897, acc:0.863158,  val_loss:0.497400, val_acc:0.800000,  val_acc-acc = -6.32%,  lr:0.000010  [47.83 sec]\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.81818\n",
            "epoch:141, loss:0.362500, acc:0.866397,  val_loss:0.497972, val_acc:0.800000,  val_acc-acc = -6.64%,  lr:0.000003  [47.92 sec]\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.81818\n",
            "epoch:142, loss:0.369091, acc:0.866127,  val_loss:0.497842, val_acc:0.797861,  val_acc-acc = -6.83%,  lr:0.000010  [47.95 sec]\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.81818\n",
            "epoch:143, loss:0.368508, acc:0.864507,  val_loss:0.498093, val_acc:0.798930,  val_acc-acc = -6.56%,  lr:0.000010  [47.79 sec]\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.81818\n",
            "epoch:144, loss:0.359419, acc:0.868286,  val_loss:0.497635, val_acc:0.796791,  val_acc-acc = -7.15%,  lr:0.000010  [47.79 sec]\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.81818\n",
            "epoch:145, loss:0.369314, acc:0.863158,  val_loss:0.498069, val_acc:0.795722,  val_acc-acc = -6.74%,  lr:0.000010  [47.88 sec]\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.81818\n",
            "epoch:146, loss:0.367955, acc:0.860999,  val_loss:0.497963, val_acc:0.796791,  val_acc-acc = -6.42%,  lr:0.000003  [47.78 sec]\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.81818\n",
            "epoch:147, loss:0.362111, acc:0.864507,  val_loss:0.498694, val_acc:0.797861,  val_acc-acc = -6.66%,  lr:0.000010  [47.73 sec]\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.81818\n",
            "epoch:148, loss:0.368416, acc:0.858300,  val_loss:0.498390, val_acc:0.800000,  val_acc-acc = -5.83%,  lr:0.000010  [47.74 sec]\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.81818\n",
            "epoch:149, loss:0.367090, acc:0.866127,  val_loss:0.498787, val_acc:0.797861,  val_acc-acc = -6.83%,  lr:0.000010  [47.79 sec]\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.81818\n",
            "epoch:150, loss:0.365960, acc:0.864777,  val_loss:0.498877, val_acc:0.796791,  val_acc-acc = -6.80%,  lr:0.000010  [47.71 sec]\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.81818\n",
            "epoch:151, loss:0.364708, acc:0.861269,  val_loss:0.498335, val_acc:0.798930,  val_acc-acc = -6.23%,  lr:0.000003  [47.51 sec]\n",
            "\n",
            "Epoch 00151: val_acc did not improve from 0.81818\n",
            "epoch:152, loss:0.362599, acc:0.864237,  val_loss:0.497934, val_acc:0.796791,  val_acc-acc = -6.74%,  lr:0.000010  [47.71 sec]\n",
            "\n",
            "Epoch 00152: val_acc did not improve from 0.81818\n",
            "epoch:153, loss:0.364822, acc:0.868556,  val_loss:0.498475, val_acc:0.796791,  val_acc-acc = -7.18%,  lr:0.000010  [47.69 sec]\n",
            "\n",
            "Epoch 00153: val_acc did not improve from 0.81818\n",
            "epoch:154, loss:0.354788, acc:0.867476,  val_loss:0.499120, val_acc:0.797861,  val_acc-acc = -6.96%,  lr:0.000010  [47.78 sec]\n",
            "\n",
            "Epoch 00154: val_acc did not improve from 0.81818\n",
            "epoch:155, loss:0.359862, acc:0.866397,  val_loss:0.497934, val_acc:0.797861,  val_acc-acc = -6.85%,  lr:0.000010  [47.71 sec]\n",
            "\n",
            "Epoch 00155: val_acc did not improve from 0.81818\n",
            "epoch:156, loss:0.375593, acc:0.857760,  val_loss:0.498554, val_acc:0.796791,  val_acc-acc = -6.10%,  lr:0.000003  [47.57 sec]\n",
            "\n",
            "Epoch 00156: val_acc did not improve from 0.81818\n",
            "epoch:157, loss:0.368480, acc:0.865047,  val_loss:0.497981, val_acc:0.797861,  val_acc-acc = -6.72%,  lr:0.000010  [47.66 sec]\n",
            "\n",
            "Epoch 00157: val_acc did not improve from 0.81818\n",
            "epoch:158, loss:0.360889, acc:0.869636,  val_loss:0.498463, val_acc:0.797861,  val_acc-acc = -7.18%,  lr:0.000010  [47.58 sec]\n",
            "\n",
            "Epoch 00158: val_acc did not improve from 0.81818\n",
            "epoch:159, loss:0.359749, acc:0.869096,  val_loss:0.498058, val_acc:0.794652,  val_acc-acc = -7.44%,  lr:0.000010  [47.80 sec]\n",
            "\n",
            "Epoch 00159: val_acc did not improve from 0.81818\n",
            "epoch:160, loss:0.368353, acc:0.864237,  val_loss:0.498837, val_acc:0.795722,  val_acc-acc = -6.85%,  lr:0.000010  [47.73 sec]\n",
            "\n",
            "Epoch 00160: val_acc did not improve from 0.81818\n",
            "epoch:161, loss:0.367763, acc:0.863158,  val_loss:0.498927, val_acc:0.795722,  val_acc-acc = -6.74%,  lr:0.000003  [47.85 sec]\n",
            "\n",
            "Epoch 00161: val_acc did not improve from 0.81818\n",
            "epoch:162, loss:0.368837, acc:0.862888,  val_loss:0.499172, val_acc:0.795722,  val_acc-acc = -6.72%,  lr:0.000001  [47.82 sec]\n",
            "\n",
            "Epoch 00162: val_acc did not improve from 0.81818\n",
            "epoch:163, loss:0.368000, acc:0.862888,  val_loss:0.498895, val_acc:0.796791,  val_acc-acc = -6.61%,  lr:0.000001  [47.40 sec]\n",
            "\n",
            "Epoch 00163: val_acc did not improve from 0.81818\n",
            "epoch:164, loss:0.364635, acc:0.864507,  val_loss:0.499022, val_acc:0.796791,  val_acc-acc = -6.77%,  lr:0.000001  [47.64 sec]\n",
            "\n",
            "Epoch 00164: val_acc did not improve from 0.81818\n",
            "epoch:165, loss:0.362559, acc:0.865047,  val_loss:0.499277, val_acc:0.795722,  val_acc-acc = -6.93%,  lr:0.000001  [47.78 sec]\n",
            "\n",
            "Epoch 00165: val_acc did not improve from 0.81818\n",
            "epoch:166, loss:0.362322, acc:0.864237,  val_loss:0.498982, val_acc:0.795722,  val_acc-acc = -6.85%,  lr:0.000000  [47.59 sec]\n",
            "\n",
            "Epoch 00166: val_acc did not improve from 0.81818\n",
            "epoch:167, loss:0.362606, acc:0.862348,  val_loss:0.498968, val_acc:0.796791,  val_acc-acc = -6.56%,  lr:0.000001  [47.65 sec]\n",
            "\n",
            "Epoch 00167: val_acc did not improve from 0.81818\n",
            "epoch:168, loss:0.366269, acc:0.860999,  val_loss:0.499032, val_acc:0.796791,  val_acc-acc = -6.42%,  lr:0.000001  [47.69 sec]\n",
            "\n",
            "Epoch 00168: val_acc did not improve from 0.81818\n",
            "epoch:169, loss:0.358525, acc:0.860459,  val_loss:0.499149, val_acc:0.796791,  val_acc-acc = -6.37%,  lr:0.000001  [47.60 sec]\n",
            "\n",
            "Epoch 00169: val_acc did not improve from 0.81818\n",
            "epoch:170, loss:0.370495, acc:0.862348,  val_loss:0.499067, val_acc:0.796791,  val_acc-acc = -6.56%,  lr:0.000001  [47.66 sec]\n",
            "\n",
            "Epoch 00170: val_acc did not improve from 0.81818\n",
            "epoch:171, loss:0.360795, acc:0.858030,  val_loss:0.499033, val_acc:0.796791,  val_acc-acc = -6.12%,  lr:0.000000  [47.72 sec]\n",
            "\n",
            "Epoch 00171: val_acc did not improve from 0.81818\n",
            "epoch:172, loss:0.361108, acc:0.872065,  val_loss:0.499413, val_acc:0.795722,  val_acc-acc = -7.63%,  lr:0.000001  [47.86 sec]\n",
            "\n",
            "Epoch 00172: val_acc did not improve from 0.81818\n",
            "epoch:173, loss:0.362150, acc:0.866397,  val_loss:0.499043, val_acc:0.796791,  val_acc-acc = -6.96%,  lr:0.000001  [47.80 sec]\n",
            "\n",
            "Epoch 00173: val_acc did not improve from 0.81818\n",
            "epoch:174, loss:0.370862, acc:0.863698,  val_loss:0.499197, val_acc:0.795722,  val_acc-acc = -6.80%,  lr:0.000001  [47.73 sec]\n",
            "\n",
            "Epoch 00174: val_acc did not improve from 0.81818\n",
            "epoch:175, loss:0.357810, acc:0.864777,  val_loss:0.499285, val_acc:0.796791,  val_acc-acc = -6.80%,  lr:0.000001  [47.56 sec]\n",
            "\n",
            "Epoch 00175: val_acc did not improve from 0.81818\n",
            "epoch:176, loss:0.359685, acc:0.865317,  val_loss:0.499230, val_acc:0.796791,  val_acc-acc = -6.85%,  lr:0.000000  [47.54 sec]\n",
            "\n",
            "Epoch 00176: val_acc did not improve from 0.81818\n",
            "epoch:177, loss:0.363901, acc:0.860729,  val_loss:0.499243, val_acc:0.796791,  val_acc-acc = -6.39%,  lr:0.000001  [47.69 sec]\n",
            "\n",
            "Epoch 00177: val_acc did not improve from 0.81818\n",
            "epoch:178, loss:0.369617, acc:0.858570,  val_loss:0.499321, val_acc:0.796791,  val_acc-acc = -6.18%,  lr:0.000001  [47.63 sec]\n",
            "\n",
            "Epoch 00178: val_acc did not improve from 0.81818\n",
            "epoch:179, loss:0.371636, acc:0.860999,  val_loss:0.499267, val_acc:0.795722,  val_acc-acc = -6.53%,  lr:0.000001  [47.58 sec]\n",
            "\n",
            "Epoch 00179: val_acc did not improve from 0.81818\n",
            "epoch:180, loss:0.364029, acc:0.865857,  val_loss:0.499287, val_acc:0.796791,  val_acc-acc = -6.91%,  lr:0.000001  [47.73 sec]\n",
            "\n",
            "Epoch 00180: val_acc did not improve from 0.81818\n",
            "epoch:181, loss:0.363373, acc:0.869906,  val_loss:0.499545, val_acc:0.796791,  val_acc-acc = -7.31%,  lr:0.000000  [47.62 sec]\n",
            "\n",
            "Epoch 00181: val_acc did not improve from 0.81818\n",
            "epoch:182, loss:0.364282, acc:0.865587,  val_loss:0.499351, val_acc:0.796791,  val_acc-acc = -6.88%,  lr:0.000000  [47.59 sec]\n",
            "\n",
            "Epoch 00182: val_acc did not improve from 0.81818\n",
            "epoch:183, loss:0.356089, acc:0.868016,  val_loss:0.499202, val_acc:0.796791,  val_acc-acc = -7.12%,  lr:0.000000  [47.56 sec]\n",
            "\n",
            "Epoch 00183: val_acc did not improve from 0.81818\n",
            "epoch:184, loss:0.361866, acc:0.863428,  val_loss:0.499452, val_acc:0.796791,  val_acc-acc = -6.66%,  lr:0.000000  [47.81 sec]\n",
            "\n",
            "Epoch 00184: val_acc did not improve from 0.81818\n",
            "epoch:185, loss:0.363508, acc:0.868016,  val_loss:0.499284, val_acc:0.796791,  val_acc-acc = -7.12%,  lr:0.000000  [47.62 sec]\n",
            "\n",
            "Epoch 00185: val_acc did not improve from 0.81818\n",
            "epoch:186, loss:0.371471, acc:0.860999,  val_loss:0.499306, val_acc:0.796791,  val_acc-acc = -6.42%,  lr:0.000000  [47.71 sec]\n",
            "\n",
            "Epoch 00186: val_acc did not improve from 0.81818\n",
            "epoch:187, loss:0.362822, acc:0.868556,  val_loss:0.499213, val_acc:0.796791,  val_acc-acc = -7.18%,  lr:0.000000  [47.94 sec]\n",
            "\n",
            "Epoch 00187: val_acc did not improve from 0.81818\n",
            "epoch:188, loss:0.359756, acc:0.866937,  val_loss:0.499286, val_acc:0.796791,  val_acc-acc = -7.01%,  lr:0.000000  [47.61 sec]\n",
            "\n",
            "Epoch 00188: val_acc did not improve from 0.81818\n",
            "epoch:189, loss:0.359613, acc:0.869096,  val_loss:0.499483, val_acc:0.796791,  val_acc-acc = -7.23%,  lr:0.000000  [47.52 sec]\n",
            "\n",
            "Epoch 00189: val_acc did not improve from 0.81818\n",
            "epoch:190, loss:0.368421, acc:0.860999,  val_loss:0.499471, val_acc:0.796791,  val_acc-acc = -6.42%,  lr:0.000000  [47.76 sec]\n",
            "\n",
            "Epoch 00190: val_acc did not improve from 0.81818\n",
            "epoch:191, loss:0.373983, acc:0.862078,  val_loss:0.499147, val_acc:0.796791,  val_acc-acc = -6.53%,  lr:0.000000  [47.98 sec]\n",
            "\n",
            "Epoch 00191: val_acc did not improve from 0.81818\n",
            "epoch:192, loss:0.367561, acc:0.858839,  val_loss:0.499305, val_acc:0.795722,  val_acc-acc = -6.31%,  lr:0.000000  [47.64 sec]\n",
            "\n",
            "Epoch 00192: val_acc did not improve from 0.81818\n",
            "epoch:193, loss:0.367021, acc:0.862618,  val_loss:0.499098, val_acc:0.796791,  val_acc-acc = -6.58%,  lr:0.000000  [47.82 sec]\n",
            "\n",
            "Epoch 00193: val_acc did not improve from 0.81818\n",
            "epoch:194, loss:0.373027, acc:0.856950,  val_loss:0.499214, val_acc:0.796791,  val_acc-acc = -6.02%,  lr:0.000000  [47.96 sec]\n",
            "\n",
            "Epoch 00194: val_acc did not improve from 0.81818\n",
            "epoch:195, loss:0.361452, acc:0.863968,  val_loss:0.499269, val_acc:0.796791,  val_acc-acc = -6.72%,  lr:0.000000  [47.56 sec]\n",
            "\n",
            "Epoch 00195: val_acc did not improve from 0.81818\n",
            "epoch:196, loss:0.371203, acc:0.864507,  val_loss:0.499364, val_acc:0.796791,  val_acc-acc = -6.77%,  lr:0.000000  [47.67 sec]\n",
            "\n",
            "Epoch 00196: val_acc did not improve from 0.81818\n",
            "epoch:197, loss:0.353746, acc:0.869096,  val_loss:0.499300, val_acc:0.796791,  val_acc-acc = -7.23%,  lr:0.000000  [47.64 sec]\n",
            "\n",
            "Epoch 00197: val_acc did not improve from 0.81818\n",
            "epoch:198, loss:0.363810, acc:0.864237,  val_loss:0.499305, val_acc:0.796791,  val_acc-acc = -6.74%,  lr:0.000000  [47.86 sec]\n",
            "\n",
            "Epoch 00198: val_acc did not improve from 0.81818\n",
            "epoch:199, loss:0.361659, acc:0.866127,  val_loss:0.499309, val_acc:0.796791,  val_acc-acc = -6.93%,  lr:0.000000  [47.66 sec]\n",
            "\n",
            "Epoch 00199: val_acc did not improve from 0.81818\n",
            "epoch:200, loss:0.356771, acc:0.864237,  val_loss:0.499277, val_acc:0.796791,  val_acc-acc = -6.74%,  lr:0.000000  [47.70 sec]\n",
            "\n",
            "Epoch 00200: val_acc did not improve from 0.81818\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.4993 - acc: 0.7968\n",
            "Test loss: 0.4992765784263611\n",
            "Test accuracy: 0.7967914342880249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlcjgwxoZh4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "56fc7d93-41d7-4e82-b23f-c9f3fd290acf"
      },
      "source": [
        "plt.figure(figsize=(10,8))\r\n",
        "plt.plot(history.history['acc'])\r\n",
        "plt.plot(history.history['val_acc'])\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('%')\r\n",
        "plt.legend(('acc','val-acc'))\r\n",
        "plt.grid(b=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoNeNGBZUTYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff42aea6-63d5-4706-fa8b-fdafbe42c7a5"
      },
      "source": [
        "test_imgs_paths = os.listdir('/content/drive/MyDrive/Xrays/test_images/')\r\n",
        "test_imgs = []\r\n",
        "for path in test_imgs_paths:\r\n",
        "  img = Image.open('/content/drive/MyDrive/Xrays/test_images/{test_image}'.format(test_image=path))\r\n",
        "  test_imgs.append(img)\r\n",
        "\r\n",
        "print(\"Loaded Test data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDja0tZehVAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9697148-9629-4763-9b9b-01e6e0afb457"
      },
      "source": [
        "for i in range(len(test_imgs_paths)):\r\n",
        "  test_imgs[i]= resize(test_imgs[i], width, height)\r\n",
        "  test_imgs[i]= np.asarray(test_imgs[i])\r\n",
        "\r\n",
        "test_imgs = np.array(test_imgs, dtype=\"float32\")/255.0\r\n",
        "\r\n",
        "print(test_imgs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1168, 270, 270, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plMbHqvQUHHE"
      },
      "source": [
        "def getMaxIndex(list):\r\n",
        "  maxim= max(list)\r\n",
        "  for i in range(len(list)):\r\n",
        "    if maxim == list[i]:\r\n",
        "      return i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnwYx7TGXWyP"
      },
      "source": [
        "predictions = model.predict(test_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxUcLvM4UVnM"
      },
      "source": [
        "import csv\r\n",
        "\r\n",
        "with open('submission_resnet8_270p_batch32(2).csv', mode='w') as submission_file:\r\n",
        "    submission_file = csv.writer(submission_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\r\n",
        "\r\n",
        "    submission_file.writerow(['file_name', 'class_id'])\r\n",
        "    j=0\r\n",
        "    for i  in predictions:\r\n",
        "      #print(\"image : {img} \\t\\tclass : {i}\".format(img=test_imgs_paths[j], i=getMaxIndex(i)))\r\n",
        "      submission_file.writerow(['{img}'.format(img=test_imgs_paths[j]), '{i}'.format(i=getMaxIndex(i))])\r\n",
        "      j+=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}