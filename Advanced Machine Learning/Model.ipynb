{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK6aVWL5hzQZ"
      },
      "source": [
        "#TO DO\r\n",
        "\r\n",
        "- ~~**change batch_size in cell [23]**~~\r\n",
        "- ~~**change epochs in cell [23]**~~\r\n",
        "- ~~**change importing image in cell [5]**~~\r\n",
        "- ~~import all train images and train~~\r\n",
        "- import test images and fit\r\n",
        "- export csv with test image results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST5bPH8F3BfM",
        "outputId": "b13edab2-582e-496f-c7cf-2f114854d76d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import time\r\n",
        "from numpy.linalg import inv, norm\r\n",
        "from IPython.display import display \r\n",
        "import pandas\r\n",
        "\r\n",
        "\r\n",
        "drive.mount(\"/content/drive\")\r\n",
        "os.chdir('/content/drive/MyDrive/Xrays/')\r\n",
        "print('\\n',os.getcwd())\r\n",
        "print(\"\\n\")\r\n",
        "print(os.listdir())\r\n",
        "\r\n",
        "save_dir = os.path.join(os.getcwd(),'saved_models')\r\n",
        "\r\n",
        "##Imports for the Learning and the plotting\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Concatenate, \\\r\n",
        "                                    AveragePooling2D, Input, Flatten, MaxPooling2D\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "\r\n",
        "\r\n",
        "##Import for preprocessing\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            " /content/drive/MyDrive/Xrays\n",
            "\n",
            "\n",
            "['labels_train.csv', 'sample_submission.csv', 'labels_train.xlsx', 'test_images', 'train_images', 'model.png', 'saved_models']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbvCbbLZ3R0r"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "def resize(image_pil, width, height):\r\n",
        "    '''\r\n",
        "    Resize PIL image keeping ratio and using white background.\r\n",
        "    '''\r\n",
        "    ratio_w = width / image_pil.width\r\n",
        "    ratio_h = height / image_pil.height\r\n",
        "    if ratio_w < ratio_h:\r\n",
        "        # It must be fixed by width\r\n",
        "        resize_width = width\r\n",
        "        resize_height = round(ratio_w * image_pil.height)\r\n",
        "    else:\r\n",
        "        # Fixed by height\r\n",
        "        resize_width = round(ratio_h * image_pil.width)\r\n",
        "        resize_height = height\r\n",
        "    image_resize = image_pil.resize((resize_width, resize_height), Image.ANTIALIAS)\r\n",
        "    background = Image.new('RGBA', (width, height), (0, 0, 0, 255))\r\n",
        "    offset = (round((width - resize_width) / 2), round((height - resize_height) / 2))\r\n",
        "    background.paste(image_resize, offset)\r\n",
        "    return background.convert('RGB')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX3g603hDaop",
        "outputId": "d195cc93-f4f7-4174-b93d-819afe8e3dcf"
      },
      "source": [
        "data= pandas.read_csv('/content/drive/MyDrive/Xrays/labels_train.csv', header=None, usecols=[0,1], names=['file_name', 'class_id'])\r\n",
        "#print(labels[1:])\r\n",
        "labels = data['class_id'].values\r\n",
        "labels = labels[1:]\r\n",
        "img_name = data['file_name'].values\r\n",
        "img_name = img_name[1:]\r\n",
        "\r\n",
        "#data_labels = np.array(data[1:])\r\n",
        "#print(data_labels.shape)   \r\n",
        "\r\n",
        "labels = np.array(labels)\r\n",
        "print(labels.shape)   \r\n",
        "print(labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4672,)\n",
            "['1' '2' '2' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCva8pf_c3jx",
        "outputId": "a34053ad-d6c0-4c69-ce20-4b199e5b3748"
      },
      "source": [
        "train_imgs = []\r\n",
        "for i in range(img_name.size):\r\n",
        "  img = Image.open('/content/drive/MyDrive/Xrays/train_images/{train_image}'.format(train_image=img_name[i]))\r\n",
        "  train_imgs.append(img)\r\n",
        "\r\n",
        "print(\"Loaded Training data\")\r\n",
        "\r\n",
        "test_imgs_paths = os.listdir('/content/drive/MyDrive/Xrays/test_images/')\r\n",
        "test_imgs = []\r\n",
        "for path in test_imgs_paths:\r\n",
        "  img = Image.open('/content/drive/MyDrive/Xrays/test_images/{test_image}'.format(test_image=path))\r\n",
        "  test_imgs.append(img)\r\n",
        "\r\n",
        "print(\"Loaded Test data\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Training data\n",
            "Loaded Test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV4NREswYRyf"
      },
      "source": [
        "for i in range(img_name.size):\r\n",
        "  train_imgs[i]= resize(train_imgs[i], 100, 100)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7OLn8SdfHHx"
      },
      "source": [
        "for i in range(img_name.size):\r\n",
        "  train_imgs[i]= np.asarray(train_imgs[i])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e22nwXUVgUy6",
        "outputId": "d281184c-500f-4f0a-ba24-ab5a9098ab5c"
      },
      "source": [
        "train_imgs = np.array(train_imgs, dtype=\"float32\")/255.0\r\n",
        "\r\n",
        "print(train_imgs.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4672, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDja0tZehVAH",
        "outputId": "77862f05-40ea-4396-fc4a-629170e5893a"
      },
      "source": [
        "for i in range(len(test_imgs_paths)):\r\n",
        "  test_imgs[i]= resize(test_imgs[i], 100, 100)\r\n",
        "  test_imgs[i]= np.asarray(test_imgs[i])\r\n",
        "\r\n",
        "test_imgs = np.array(test_imgs, dtype=\"float32\")/255.0\r\n",
        "\r\n",
        "print(test_imgs.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1176, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbZC01ZN8UGU",
        "outputId": "03235f28-f451-45a4-f89a-a03a26cd4266"
      },
      "source": [
        "depth = 20\r\n",
        "\r\n",
        "x_train = train_imgs\r\n",
        "y_train = labels\r\n",
        "x_test = test_imgs\r\n",
        "y_test = data_labels_test\r\n",
        "num_classes = 3\r\n",
        "\r\n",
        "#datagen.flow(x_train, t_train, batch_size=batch_size), \r\n",
        "#                    validation_data=(x_test, t_test),\r\n",
        "\r\n",
        "input_shape = x_train.shape[1:]\r\n",
        "\r\n",
        "x_train_mean = np.mean(x_train, axis=0)\r\n",
        "x_train -= x_train_mean\r\n",
        "x_test -= x_train_mean\r\n",
        "\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "\r\n",
        "t_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "t_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "print('y_train (labels) shape:', y_train.shape)\r\n",
        "print('t_train (one-hot rep) shape:', t_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (1, 720, 1080, 3)\n",
            "1 train samples\n",
            "1 test samples\n",
            "y_train (labels) shape: (1, 1)\n",
            "t_train (one-hot rep) shape: (1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0VZB6i-Z_ih",
        "outputId": "9cbd33f8-70e3-4a29-afb2-8094c79b221e"
      },
      "source": [
        "print(t_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksB30HrvWXFb"
      },
      "source": [
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True):\r\n",
        "    conv = Conv2D(num_filters,\r\n",
        "                  kernel_size=kernel_size,\r\n",
        "                  strides=strides,\r\n",
        "                  padding='same',\r\n",
        "                  kernel_initializer='he_normal',\r\n",
        "                  kernel_regularizer=l2(1e-4))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAUYakbsWjKJ"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=3):\r\n",
        "    if (depth - 2) % 6 != 0:\r\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs)\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             strides=strides)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             activation=None)\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters,\r\n",
        "                                 kernel_size=2, ### originally: 1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "            \r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\r\n",
        "    x = MaxPooling2D(pool_size=8)(x)\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',\r\n",
        "                    kernel_initializer='he_normal')(y)\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    print('Model parameters: {:d}'.format(model.count_params()))\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jCC3ta_XDwD"
      },
      "source": [
        "def lr_schedule(epoch):\r\n",
        "  lr = 1e-3\r\n",
        "  if (epoch>180) :\r\n",
        "      lr *= 0.5e-3\r\n",
        "  elif epoch > 160:\r\n",
        "      lr *= 1e-3\r\n",
        "  elif epoch > 120:\r\n",
        "      lr *= 1e-2\r\n",
        "  elif epoch > 80:\r\n",
        "      lr *= 1e-1\r\n",
        "  return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTIqCW5XXbMj"
      },
      "source": [
        "class MyCallback(keras.callbacks.Callback):\r\n",
        "    tstart = None\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_train_end(self, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_epoch_begin(self, epoch, logs={}):\r\n",
        "        self.tstart = time.time()\r\n",
        "        print('epoch:{:03d}'.format(epoch+1), end=', ')\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        print('loss:{:8.6f}, acc:{:8.6f},  val_loss:{:8.6f}, val_acc:{:8.6f},  val_acc-acc = {:5.2f}%,  lr:{:0.6f}  [{:0.2f} sec]'.format(\r\n",
        "                logs.get('loss'), logs.get('acc'),\r\n",
        "                logs.get('val_loss'), logs.get('val_acc'),\r\n",
        "                100*(logs.get('val_acc')-logs.get('acc')),\r\n",
        "                K.eval(self.model.optimizer.lr),\r\n",
        "                time.time()-self.tstart))\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_batch_begin(self, batch, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_batch_end(self, batch, logs={}):\r\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvh5AxtvXi3C"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)\r\n",
        "    \r\n",
        "model.compile(loss=\"categorical_crossentropy\",\r\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\r\n",
        "              metrics=['acc'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67on7ovvYJnR"
      },
      "source": [
        "plot_model(model, show_shapes=True, dpi=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgSMdRbWYVyR"
      },
      "source": [
        "# Training parameters\r\n",
        "batch_size = 64  # orig paper trained all networks with batch_size=128\r\n",
        "epochs = 200\r\n",
        "\r\n",
        "# Prepare model model saving directory.\r\n",
        "model_name = 'resnet20-e{epoch:04d}-loss{loss:.3f}-acc{acc:.3f}-valloss{val_loss:.3f}-valacc{val_acc:.3f}.h5'\r\n",
        "if not os.path.isdir(save_dir):\r\n",
        "    os.makedirs(save_dir)\r\n",
        "filepath = os.path.join(save_dir, model_name)\r\n",
        "\r\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\r\n",
        "                             monitor='val_acc',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "\r\n",
        "# This will do preprocessing and realtime data augmentation:\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    # set input mean to 0 over the dataset\r\n",
        "    featurewise_center=False,\r\n",
        "    # set each sample mean to 0\r\n",
        "    samplewise_center=False,\r\n",
        "    # divide inputs by std of dataset\r\n",
        "    featurewise_std_normalization=False,\r\n",
        "    # divide each input by its std\r\n",
        "    samplewise_std_normalization=False,\r\n",
        "    # apply ZCA whitening\r\n",
        "    zca_whitening=False,\r\n",
        "    # epsilon for ZCA whitening\r\n",
        "    zca_epsilon=1e-06,\r\n",
        "    # randomly rotate images in the range (deg 0 to 180)\r\n",
        "    rotation_range=0,\r\n",
        "    # randomly shift images horizontally\r\n",
        "    width_shift_range=0.1,\r\n",
        "    # randomly shift images vertically\r\n",
        "    height_shift_range=0.1,\r\n",
        "    # set range for random shear\r\n",
        "    shear_range=0.,\r\n",
        "    # set range for random zoom\r\n",
        "    zoom_range=0.,\r\n",
        "    # set range for random channel shifts\r\n",
        "    channel_shift_range=0.,\r\n",
        "    # set mode for filling points outside the input boundaries\r\n",
        "    fill_mode='nearest',\r\n",
        "    # value used for fill_mode = \"constant\"\r\n",
        "    cval=0.,\r\n",
        "    # randomly flip images\r\n",
        "    horizontal_flip=True,\r\n",
        "    # randomly flip images\r\n",
        "    vertical_flip=False,\r\n",
        "    # set rescaling factor (applied before any other transformation)\r\n",
        "    rescale=None,\r\n",
        "    # set function that will be applied on each input\r\n",
        "    preprocessing_function=None,\r\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\r\n",
        "    data_format=None,\r\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\r\n",
        "    validation_split=0.0)\r\n",
        "\r\n",
        "# Compute quantities required for featurewise normalization\r\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "datagen.fit(x_train)\r\n",
        "\r\n",
        "\r\n",
        "# Fit the model on the batches generated by datagen.flow().\r\n",
        "history = model.fit(datagen.flow(x_train, t_train, batch_size=batch_size), \r\n",
        "                    validation_data=(x_test, t_test), epochs=epochs, verbose=0, \r\n",
        "                    workers=4, steps_per_epoch = int(x_train.shape[0]/batch_size), \r\n",
        "                    callbacks=[lr_reducer, lr_scheduler, MyCallback(), checkpoint])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bgCHlN1ZJlY"
      },
      "source": [
        "# Score trained model.\r\n",
        "scores = model.evaluate(x_test, t_test, verbose=1)\r\n",
        "print('Test loss:', scores[0])\r\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "mlcjgwxoZh4Z",
        "outputId": "20a5638b-2518-47f2-9fed-abaa7381e1d6"
      },
      "source": [
        "plt.figure(figsize=(10,8))\r\n",
        "plt.plot(history.history['acc'])\r\n",
        "plt.plot(history.history['val_acc'])\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('%')\r\n",
        "plt.legend(('acc','val-acc'))\r\n",
        "plt.grid(b=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}